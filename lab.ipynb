{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Lab\n",
    "\n",
    "## We will build and evaluate a Question Answering Expert for a fictional company: InsureLLM!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEFORE WE BEGIN:\n",
    "\n",
    "Look at the knowledge-base - this is the company shared drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from IPython.display import Markdown, display\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4.1-nano\"\n",
    "db_name = \"vector_db\"\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_base_path = \"knowledge-base/**/*.md\"\n",
    "files = glob.glob(knowledge_base_path, recursive=True)\n",
    "print(f\"Found {len(files)} files in the knowledge base\")\n",
    "\n",
    "entire_knowledge_base = \"\"\n",
    "\n",
    "for file_path in files:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        entire_knowledge_base += f.read()\n",
    "        entire_knowledge_base += \"\\n\\n\"\n",
    "\n",
    "print(f\"Total characters in knowledge base: {len(entire_knowledge_base):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model(MODEL)\n",
    "tokens = encoding.encode(entire_knowledge_base)\n",
    "token_count = len(tokens)\n",
    "print(f\"Total tokens for gpt-4.1-mini: {token_count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain Document Loaders\n",
    "\n",
    "Loading in the data and splitting it into chunks using LangChain's helper classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = glob.glob(\"knowledge-base/*\")\n",
    "\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs={'encoding': 'utf-8'})\n",
    "    folder_docs = loader.load()\n",
    "    for doc in folder_docs:\n",
    "        doc.metadata[\"doc_type\"] = doc_type\n",
    "        documents.append(doc)\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Divided into {len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "#embeddings = OpenAIEmbeddings()\n",
    "\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many documents are in the vector store? How many dimensions?\n",
    "\n",
    "collection = vectorstore._collection\n",
    "count = collection.count()\n",
    "\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"There are {count:,} vectors with {dimensions:,} dimensions in the vector store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather the vectors, documents and metadata\n",
    "\n",
    "result = collection.get(include=['embeddings', 'documents', 'metadatas'])\n",
    "vectors = np.array(result['embeddings'])\n",
    "documents = result['documents']\n",
    "metadatas = result['metadatas']\n",
    "doc_types = [metadata['source'].split('/')[1] for metadata in metadatas]\n",
    "colors = [['blue', 'green', 'red', 'orange'][['products', 'employees', 'contracts', 'company'].index(t)] for t in doc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We humans find it easier to visalize things in 2D!\n",
    "# Reduce the dimensionality of the vectors to 2D using t-SNE\n",
    "# (t-distributed stochastic neighbor embedding)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "# Create the 2D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color=colors, opacity=0.8),\n",
    "    text=[f\"Type: {t}<br>Text: {d[:100]}...\" for t, d in zip(doc_types, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='2D Chroma Vector Store Visualization',\n",
    "    scene=dict(xaxis_title='x',yaxis_title='y'),\n",
    "    width=800,\n",
    "    height=600,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try 3D!\n",
    "\n",
    "tsne = TSNE(n_components=3, random_state=42)\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "# Create the 3D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    z=reduced_vectors[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color=colors, opacity=0.8),\n",
    "    text=[f\"Type: {t}<br>Text: {d[:100]}...\" for t, d in zip(doc_types, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='3D Chroma Vector Store Visualization',\n",
    "    scene=dict(xaxis_title='x', yaxis_title='y', zaxis_title='z'),\n",
    "    width=900,\n",
    "    height=700,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain Code to Call OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=MODEL)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# Define our system prompt template\n",
    "SYSTEM_PROMPT_TEMPLATE = \"\"\"Answer the question based on the context:\n",
    "\n",
    "Context:\n",
    "{context}\"\"\"\n",
    "\n",
    "def answer_question(question: str) -> tuple[str, list]:\n",
    "    docs = retriever.invoke(question, k=5)\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    system_prompt = SYSTEM_PROMPT_TEMPLATE.format(context=context)\n",
    "    \n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=question)\n",
    "    ])\n",
    "    \n",
    "    return response.content, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Please explain what Insurellm is in a couple of sentences\"\n",
    "answer, context_docs = answer_question(query)\n",
    "\n",
    "print(f\"Question: {query}\\n\")\n",
    "print(f\"Answer: {answer}\\n\")\n",
    "print(f\"Used {len(context_docs)} documents for context\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHALLENGE:\n",
    "\n",
    "You will be changing or replacing 2 modules:\n",
    "\n",
    "`ingest.py`\n",
    "\n",
    "`answer.py`\n",
    "\n",
    "They are VERY simple! Let's look at them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now check out ingest.py\n",
    "\n",
    "Then run at the terminal:\n",
    "\n",
    "`uv run ingest.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 413 vectors with 384 dimensions in the vector store\n",
      "Ingestion complete\n"
     ]
    }
   ],
   "source": [
    "!uv run implementation/ingest.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now check out answer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='6c301db2-3852-42bf-85e5-870caca134bf', metadata={'doc_type': 'employees', 'source': 'knowledge-base/employees/Avery Lancaster.md'}, page_content=\"## Other HR Notes\\n- **Professional Development**: Avery has actively participated in leadership training programs and industry conferences, representing Insurellm and fostering partnerships.  \\n- **Diversity & Inclusion Initiatives**: Avery has championed a commitment to diversity in hiring practices, seeing visible improvements in team representation since 2021.  \\n- **Work-Life Balance**: Feedback revealed concerns regarding work-life balance, which Avery has approached by implementing flexible working conditions and ensuring regular check-ins with the team.\\n- **Community Engagement**: Avery led community outreach efforts, focusing on financial literacy programs, particularly aimed at underserved populations, improving Insurellm's corporate social responsibility image.  \\n\\nAvery Lancaster has demonstrated resilience and adaptability throughout her career at Insurellm, positioning the company as a key player in the insurance technology landscape.\"),\n",
       " Document(id='505da845-0049-4113-8d30-e5738ab2390b', metadata={'source': 'knowledge-base/employees/Avery Lancaster.md', 'doc_type': 'employees'}, page_content='- **2022**: **Satisfactory**  \\n  Avery focused on rebuilding team dynamics and addressing employee concerns, leading to overall improvement despite a saturated market.  \\n\\n- **2023**: **Exceeds Expectations**  \\n  Market leadership was regained with innovative approaches to personalized insurance solutions. Avery is now recognized in industry publications as a leading voice in Insurance Tech innovation.'),\n",
       " Document(id='3015e615-20e5-4561-b222-01a90ed8d2c7', metadata={'source': 'knowledge-base/employees/Avery Lancaster.md', 'doc_type': 'employees'}, page_content=\"- **2018**: **Exceeds Expectations**  \\n  Under Avery’s pivoted vision, Insurellm launched two new successful products that significantly increased market share.  \\n\\n- **2019**: **Meets Expectations**  \\n  Steady growth, however, some team tensions led to a minor drop in employee morale. Avery recognized the need to enhance company culture.  \\n\\n- **2020**: **Below Expectations**  \\n  The COVID-19 pandemic posed unforeseen operational difficulties. Avery faced criticism for delayed strategy shifts, although efforts were eventually made to stabilize the company.  \\n\\n- **2021**: **Exceptional**  \\n  Avery's decisive transition to remote work and rapid adoption of digital tools led to record-high customer satisfaction levels and increased sales.  \\n\\n- **2022**: **Satisfactory**  \\n  Avery focused on rebuilding team dynamics and addressing employee concerns, leading to overall improvement despite a saturated market.\"),\n",
       " Document(id='2bc05def-1174-49e7-9e98-725a71a581fa', metadata={'source': 'knowledge-base/employees/Avery Lancaster.md', 'doc_type': 'employees'}, page_content='# Avery Lancaster\\n\\n## Summary\\n- **Date of Birth**: March 15, 1985\\n- **Job Title**: Co-Founder & Chief Executive Officer (CEO)\\n- **Location**: San Francisco, California\\n- **Current Salary**: $225,000  \\n\\n## Insurellm Career Progression\\n- **2015 - Present**: Co-Founder & CEO  \\n  Avery Lancaster co-founded Insurellm in 2015 and has since guided the company to its current position as a leading Insurance Tech provider. Avery is known for her innovative leadership strategies and risk management expertise that have catapulted the company into the mainstream insurance market.  \\n\\n- **2013 - 2015**: Senior Product Manager at Innovate Insurance Solutions  \\n  Before launching Insurellm, Avery was a leading Senior Product Manager at Innovate Insurance Solutions, where she developed groundbreaking insurance products aimed at the tech sector.'),\n",
       " Document(id='1502408e-1eea-40c1-b101-ab1190e8e7e6', metadata={'source': 'knowledge-base/employees/Avery Lancaster.md', 'doc_type': 'employees'}, page_content=\"- **2010 - 2013**: Business Analyst at Edge Analytics  \\n  Prior to joining Innovate, Avery worked as a Business Analyst, focusing on market trends and consumer preferences in the insurance space. This position laid the groundwork for Avery’s future entrepreneurial endeavors.\\n\\n## Annual Performance History\\n- **2015**: **Exceeds Expectations**  \\n  Avery’s leadership during Insurellm's foundational year led to successful product launches and securing initial funding.  \\n\\n- **2016**: **Meets Expectations**  \\n  Growth continued, though challenges arose in operational efficiency that required Avery's attention.  \\n\\n- **2017**: **Developing**  \\n  Market competition intensified, and monthly sales metrics were below targets. Avery implemented new strategies which required a steep learning curve.  \\n\\n- **2018**: **Exceeds Expectations**  \\n  Under Avery’s pivoted vision, Insurellm launched two new successful products that significantly increased market share.\")]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from implementation.answer import fetch_context, answer_question\n",
    "\n",
    "fetch_context(\"Who is Avery?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Markdown' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m result, chunks = \u001b[38;5;28;01mawait\u001b[39;00m answer_question(\u001b[33m\"\u001b[39m\u001b[33mWho is Avery?\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m display(\u001b[43mMarkdown\u001b[49m(result))\n",
      "\u001b[31mNameError\u001b[39m: name 'Markdown' is not defined"
     ]
    }
   ],
   "source": [
    "result, chunks = await answer_question(\"Who is Avery?\")\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now check out app.py\n",
    "\n",
    "As long as you keep the same 2 functions in `answer.py`, this UI will keep working!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv run app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OK - Now it's time to EVALUATE!\n",
    "\n",
    "### First check out tests.jsonl for all the questions\n",
    "\n",
    "And see how it's loaded in test.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test import load_tests\n",
    "\n",
    "test_data = load_tests()\n",
    "\n",
    "print(len(test_data))\n",
    "print(test_data[0])\n",
    "print(test_data[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(test.category for test in test_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now take a look at eval.py\n",
    "\n",
    "test_data[0] is a very hard question that it sometimes gets wrong  \n",
    "test_data[1] is an easy question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import evaluate_retrieval, evaluate_answer\n",
    "\n",
    "evaluate_retrieval(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await evaluate_answer(test_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AND FINALLY - all come together in a UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv run evaluator.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas for your experiments\n",
    "\n",
    "### Quick wins\n",
    "\n",
    "- Experiment with the encoder\n",
    "- Experiment with chunking strategies\n",
    "\n",
    "### Big change ideas\n",
    "\n",
    "1. Pre-processing - use an LLM to rewrite (a) the chunks and/or (b) the questions / conversation history\n",
    "2. Hierarchical RAG - summarize at different levels and do RAG over summaries\n",
    "3. Tools!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 RAG Techniques\n",
    "\n",
    "1. **Chunking R&D:** experiment with chunking strategy to optimize for your commercial goal\n",
    "2. **Encoder R&D:** select the best Encoder model based on a test set\n",
    "3. **Improve Prompts:** general content, the current date, relevant context and history\n",
    "4. **Document pre-processing:** use an LLM to make the chunks and/or text for encoding\n",
    "5. **Query rewriting:** use an LLM to convert the user’s question to a RAG query\n",
    "6. **Query expansion:** use an LLM to turn the question into multiple RAG queries\n",
    "7. **Re-ranking:** use an LLM to sub-select from RAG results\n",
    "8. **Hierarchical:** use an LLM to summarize at multiple levels\n",
    "9. **Graph RAG:** retrieve content closely related to similar documents\n",
    "10. **Agentic RAG:** use Agents for retrieval, combining with Memory and Tools such as SQL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 hard questions that can be addressed with the above:\n",
    "\n",
    "- Who won the IIOTY award in 2023?\n",
    "\n",
    "- What proportion of employees have a salary over $90,000?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
